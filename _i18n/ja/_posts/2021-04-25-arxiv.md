---
layout: post
title: Robot Program Parameter Inference via Differentiable Shadow Program Inversion メモ
subtitle: 論文メモ
category: 論文
---

[論文]http://arxiv.org/abs/2103.14452), ICRA2021

---

論文内容
===

DNNによるinterpreterの模倣とgradient descentによる最適化を組み合わせた手法の提案。
一般的なProgram Synthesisではなく、ロボットのプログラムにおけるパラメータのチューニングが目的となっている。


背景
---

ロボットのプログラミングでは、複数の機能 (skill) を組み合わせて所望の動作を実現することが一般的である。skillにはおのおのパラメータがありチューニングが必要となる。
人手によるパラメータチューニングでは何度も試行錯誤する必要があり、これを自動化することができるとロボットのプログラミングを簡単にすることができる。

微分可能プログラミング (Differentiable Programming) はパラメータチューニングを効率化できる可能性がある。プログラムが微分可能であれば、gradient basedな最適化手法によりパラメータを更新し、最適なパラメータを見つけることができる。
一方で、「プログラムが微分可能である」という制約は現実的でなく、多くのロボットプログラムのskillは微分可能な実装は普通存在しない。


提案手法
---

ロボットのSkillをDNNで模倣することで微分可能な実装を作り、これを用いてパラメータ最適化を行う手法を提案した。

DNNの学習はSkillで完結して行い、skillの組み合わせはDNNのstackで実現する。skillの組み合わせを直接DNNで模倣しないことで学習すべき問題を簡潔にできている。


評価
---

ロボットプログラムのベンチマーク詳しくなくて土地勘がない。



メモ・コメント
===

Program Synthesisという立場から見ると、「計算グラフ (呼び出す関数と呼び出し順) は固定で入力の定数だけ合成する」という問題設定のように見える。
templateの穴埋めみたいなケースを考えるとロボットプログラム以外のProgram Synthesisでも活用できる場面はありそう。

この論文における「各skillを1つのDNNで模倣し、その組み合わせはDNNのstackで模倣する」という方針は凄いpromisingに見える。この方針の利点は、1) 関数の組み合わせを考えなくてよいので学習が簡単、2) 各DNNが十分精度よくプログラムを近似できていればそれらの組み合わせの精度もある程度保証される、の2つがあると思う。2は長いプログラムのProgram Synthesisでかなり重要になるのではないかという予想。
