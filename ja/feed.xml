<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="ja"><generator uri="https://jekyllrb.com/" version="4.2.0">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" hreflang="ja" /><updated>2025-01-04T17:22:46+09:00</updated><id>/feed.xml</id><title type="html">Hiroaki Mikami</title><subtitle></subtitle><entry><title type="html">Neural Program Synthesis with Priority Queue Training メモ</title><link href="/ja/2021/06/13/arxiv.html" rel="alternate" type="text/html" title="Neural Program Synthesis with Priority Queue Training メモ" /><published>2021-06-13T00:00:00+09:00</published><updated>2021-06-13T00:00:00+09:00</updated><id>/ja/2021/06/13/arxiv</id><content type="html" xml:base="/ja/2021/06/13/arxiv.html"><![CDATA[<p><a href="https://arxiv.org/abs/1801.03526">論文</a></p>

<hr />

<h1 id="論文内容">論文内容</h1>

<p>Program Synthesisに機械学習を適用する際、specificationとground truthプログラムが揃ったデータセットの用意が課題となる。強化学習を用いることでそれ以外のデータセットに対してもProgram Synthesisの学習を可能とした。RLの性能をあげるための学習アルゴリズムを提案した。</p>

<h2 id="背景">背景</h2>

<p>Program Synthesisに機械学習/DNNを適用する際、入力となるspecificationと出力となるground truthプログラムが揃ったデータセットが必要となる。また、既存研究ではsynthesize対象の言語を制約の強いDSLに絞っている。</p>

<p>強化学習を用いてProgram Synthesisをすることを考えると、必要なのはreward functionだけとなる。reward functionを計算するためにはground truthプログラムは必須ではない。</p>

<p>このため、RLの活用によってより広い範囲のProgram Synthesisに機械学習/DNNを適用することが可能となると考えられる。この論文では、RLを利用したProgram Synthesisの方法を提案した。</p>

<h2 id="提案手法">提案手法</h2>

<p>基礎となるのは通常のpolicy gradientなRL (REINFORCE) である。</p>

<p>提案手法 (Priority Queue Training) では、REINFORCEのlossに加えtopk lossを最適化の目的関数に追加 (加算) している。topk lossは今までの学習中でrewardが高かったtop k個のプログラムに対するlog liklihoodである。</p>

<h2 id="評価">評価</h2>

<p>BFに対するProgram Synthesisで提案手法を評価した。遺伝的アルゴリズムやPriority Queue Traininigを用いないRLに比べ、提案手法はより多くのケースでtest caseをpassするプログラムを生成できた。また、topk lossだけで学習しREINFORCEのlossをなくしても性能が劣化しないことを明らかにした。</p>

<h1 id="メモコメント">メモ・コメント</h1>

<p>“3. Approach”にあるDNNモデルの図を見ると、encoderはなくdecoderだけからなるDNNを用いているらしい。したがって、test caseの入出力は本当に一切見ずにrewardだけから正しいプログラムを探す、という問題設定で手法の設計・評価をしている。</p>

<p>合成ごとに学習を回すというのはかなり時間がかかるはず。また、人間の行うプログラミングを考えても仕様の情報を陽に使わないというのは無理があるように思う。</p>

<p>一方で、「推論時に強化学習のような枠組みで正しいプログラムを探索する」というのはProgram Synthesisの性能を上げる上で効果的かもしれないと思う。むやみにbeam searchのbeam sizeを上げるよりは効率よく探索できる可能性がありそう。</p>]]></content><author><name></name></author><summary type="html"><![CDATA[論文]]></summary></entry><entry><title type="html">Measuring Coding Challenge Competence With APPS メモ</title><link href="/ja/2021/05/30/arxiv.html" rel="alternate" type="text/html" title="Measuring Coding Challenge Competence With APPS メモ" /><published>2021-05-30T00:00:00+09:00</published><updated>2021-05-30T00:00:00+09:00</updated><id>/ja/2021/05/30/arxiv</id><content type="html" xml:base="/ja/2021/05/30/arxiv.html"><![CDATA[<p><a href="https://arxiv.org/abs/2105.09938">論文</a></p>

<hr />

<h1 id="論文内容">論文内容</h1>

<p>現在 (2021年の) のDNNが、競技プログラミングの問題を自動回答する能力があるかを実験によって調査した。</p>

<h2 id="背景">背景</h2>

<p>BERTに始まる巨大なDNNモデルによる言語処理は近年様々なタスクで用いられている。プログラミングにおいても、プログラミング言語間の変換やコンパイルエラーの修正タスクにおいて巨大なDNNモデルをもちいた手法が提案されている。</p>

<p>しかし、コーディングタスク (Program Synthesis, Programming by Example) では巨大なDNNモデルは殆ど用いられていない。</p>

<h2 id="実験">実験</h2>

<h3 id="データセット">データセット</h3>

<p>AtCoderやCodeforcesなどの競技プログラミングのサイトからデータセットを作成した。問題は全部で約1万問で解答言語はPython。サイト間での入力形式の違いなどはデータセットの時点で統一している。</p>

<p>収集した問題をIntroductory, Interview, Competitionの3レベルに分類した。Introductoryは1-2年のプログラミング経験があれば解けるようなアルゴリズム・データ構造の知識が必要ないもの、Interviewはcoding interviewで問われるようなレベルのアルゴリズム・データ構造の知識が必要なもの、Competitionはさらに難しい知識が必要なもの、というのが大まかな分類となる。</p>

<h3 id="dnnモデル">DNNモデル</h3>

<p>GPT-2、GPT-3、GPT-Neoの3種類のモデルで実験を行った。</p>

<p>GPT-2は、GitHub corpusによるpretrainののち、提案データセットによるfine-tuneを行った。GPT-Neoは公開されているpretrain modelから提案データセットによるfine-tuneを行った。GPT-3は公開されているpretrain modelをそのまま利用した。</p>

<h3 id="結果">結果</h3>

<p>最も多くの問題を解けたのはGPT-Neoで、Introductoryプログラムの15%のテストケースをpassした。ただし、全テストケースをpassした問題の割合で言うと3.9%となる。
問題難易度が上がるにつれて正答率が減少しており、このことはDNNが解答の暗記をしているのではないことを示唆している。</p>

<p>その他、DNNによるProgram Synthesisに関して以下の知見を得た。</p>

<ul>
  <li>fine-tuningとモデルサイズの増加によりsyntax errorの割合が劇的に減少する</li>
  <li>従来のProgram Synthesisでmetricとして良く用いられたBLEUは、test caseのpass rateと相関がなく有効な指標とは言えない</li>
</ul>

<h1 id="メモコメント">メモ・コメント</h1>

<p>あるドメインのデータセットを十分な数集められれば巨大DNNモデルによってscratchからのProgram Synthesisが可能になる可能性を示した点で面白い結果と思う。また、GPT-3以後few-shot learningに注目がいきがちな印象があったなかで、fine-tuningの重要性を再確認させる報告でもある。</p>

<p>一方で、結果の解釈は少し慎重に行った方がいいのかなと感じている。</p>

<p>例えば、</p>

<blockquote>
  <p>問題難易度が上がるにつれて正答率が減少しており、このことはDNNが解答の暗記をしているのではないことを示唆している。
Memorization is an implausible explanation as performance tracks problem difficulty; were models
just memorizing, we would expect uniform performance across difficulties.(原文)</p>
</blockquote>

<p>については、難易度の低い問題ほどバリエーションが少なく暗記しやすかった・パターンマッチで解きやすかった、という可能性はあるのではないかと思う。</p>

<p>また、</p>

<blockquote>
  <p>GPT-Neoで、Introductoryプログラムの15%のテストケースをpassした。
Note that for Introductory questions, GPT-Neo passes approximately 15% of the test cases. (原文)</p>
</blockquote>

<p>についてももう少しちゃんと見ないといけない気がする。
競技プログラミングの問題の一部はYes/Noを答えるように出力のパターンが決まっているものがある。そのような問題は例えば <code class="language-plaintext highlighter-rouge">print("Yes")</code>としておけば約50%のtestcaseにpassできることになる。実際に正解したtestcaseのうち何%がこのようなパターンなのかは気になる。</p>

<p>もうひとつ気になる点はmulti modalなprogram synthesisの効果。
今回の実験は問題文だけを入力としてプログラミングしているが、競技プログラミングの場合Input/Output exampleも同時に与えられることが一般的である。人間がプログラミングする場合を考えるとInput/Output exampleを用いることでかなり正答率を上げられる気がする。
ただ、そのような自然言語以外の入力を使うにはまだDNNモデルの改良が必要ではありそう。</p>

<p>気になる点は上記のようにあるが、とはいえProgram Synthesisも大量のデータを集めればある程度の性能は達成できそう、という見込みがでたのは大きな前進じゃないかと感じている。</p>]]></content><author><name></name></author><summary type="html"><![CDATA[論文]]></summary></entry><entry><title type="html">Synthesize, Execute and Debug Learning to Repair for Neural Program Synthesis メモ</title><link href="/ja/2021/05/16/arxiv.html" rel="alternate" type="text/html" title="Synthesize, Execute and Debug Learning to Repair for Neural Program Synthesis メモ" /><published>2021-05-16T00:00:00+09:00</published><updated>2021-05-16T00:00:00+09:00</updated><id>/ja/2021/05/16/arxiv</id><content type="html" xml:base="/ja/2021/05/16/arxiv.html"><![CDATA[<p><a href="https://arxiv.org/abs/2007.08095">論文</a>, NeurIPS2020</p>

<hr />

<h1 id="論文内容">論文内容</h1>

<p>Program Synthesisの性能を上げるために、一度SynthesizeしたプログラムをDNNによってrefinementする手法を提案した。</p>

<h2 id="背景">背景</h2>

<p>DNNによるProgram Synthesis (主にProgramming by Example) には大きく2つの種類がある。</p>

<ol>
  <li>実行途中のプログラムの状態を用いてプログラムを逐次生成するもの</li>
  <li>実行途中の状態をもちいず一気にプログラムを生成するもの</li>
</ol>

<p>1はsequentialなプログラムの実行には適しているが、ループや分岐のようなcontrol flowを扱うことができないという問題がある。2は、それまで生成したプログラムの情報を使うことができないという問題がある。</p>

<p>人間がプログラミングをやる時の事を考えると、ループや分岐を用いることは多いし、一度書いたプログラムをデバッグしながら正しいプログラムとしていく方が一般的である。このような人間のプログラミング能力を現在のProgram Synthesis技術は模倣できない。</p>

<h2 id="提案手法">提案手法</h2>

<p>DNNを用いプログラムのdebugをするcomponentを追加することで、Program Synthesisの性能を上げる手法を提案した。</p>

<p>出発点となるプログラムを生成するためのProgram Synthesis手法には特に制約はなく、任意の手法を用いることができる。ここで生成したプログラムがtestcaseをpassしない場合、提案するdebug componentによりプログラムを修正する。</p>

<p>プログラムの修正は (現在のプログラム, I/O example, プログラムの実行Trace)の3つを入力として受け取りtokenの追加・削除・変更を実行することで行う。token単位での編集なので同時に複数tokenの追加・削除・変更を行うことができるような設定をしている。そうでないと例えば <code class="language-plaintext highlighter-rouge">if</code>や <code class="language-plaintext highlighter-rouge">while</code>のような処理を追加することができないはずである。</p>

<p>学習では、正しいプログラムにmutationを加えて間違ったプログラムを用意し、これを用いて教師あり学習を行う。</p>

<h2 id="評価">評価</h2>

<p><a href="https://msr-redmond.github.io/karel-dataset/">Karelというベンチマークデータセット</a>によって評価を行った。test caseのpass率を指標として評価し、debug componentの追加によってpass率が2pt～23pt向上することを示した。</p>

<h1 id="メモコメント">メモ・コメント</h1>

<p>アイデアとしては自然で有望そうに思えたが、性能向上がそこまででもないなぁという印象を受けた。Table1, Table2を組み合わせると、EGNPSで探索回数を増やした方が性能が良かったりする可能性はありそうな気がする。</p>]]></content><author><name></name></author><summary type="html"><![CDATA[論文, NeurIPS2020]]></summary></entry><entry><title type="html">Neural Programming by Exampleのデータセットについて思うこと</title><link href="/ja/2021/05/09/program-synthesis.html" rel="alternate" type="text/html" title="Neural Programming by Exampleのデータセットについて思うこと" /><published>2021-05-09T00:00:00+09:00</published><updated>2021-05-09T00:00:00+09:00</updated><id>/ja/2021/05/09/program-synthesis</id><content type="html" xml:base="/ja/2021/05/09/program-synthesis.html"><![CDATA[<p>(DNNを用いた) Programming by Exampleについて、この1カ月くらいで考えていたことをまとめる。</p>

<p>ずっとDNNの手法の方を調査したり実験したりしてきたが、このGWで色々行き詰ってきてデータセットのことを考えたほうが良いのではないかと思いつつある。</p>

<h3 id="programming-by-exampleのデータセットの種類">Programming by Exampleのデータセットの種類</h3>

<p>DNNによるProgramming by Exampleには今のところデファクトのデータセットは今のところ存在しない。<a href="https://openreview.net/forum?id=ByldLrqlx">DeepCoder</a>で使用された整数リストに対するDSL、<a href="https://msr-redmond.github.io/karel-dataset/">Karel</a>(特定の状態を実現するようロボットを移動させる)、<a href="https://arxiv.org/abs/1703.07469">RobustFill</a>で使われた文字列変換のデータセット、あたりを用いる論文が多い印象がある。また、3D形状をプログラムであらわす (CSGみたいな) タスクの場合はShapeNetなどの3Dモデルのデータセットが用いられている。</p>

<p>RobustFill, ShapeNetを除いて、ランダムに生成したプログラムとI/O exampleでデータセットを構成している。データセットをランダム生成できるのはProgramming by Exampleの大きな利点と言える。データセットのランダム生成というと多くの場合ground truthのannotationがネックになるが、Programming by Exampleの場合は処理系があれば比較的簡単にannotationを追加できる。</p>

<h3 id="ランダム生成データセットの問題">ランダム生成データセットの問題</h3>

<p>この手のランダム生成データセットのsampleを見るとIn/Out exampleとground truthのプログラムがパッと自分には結びつかないサンプルが多かった。人間がsampleを作る場合、「これをヒントに<code class="language-plaintext highlighter-rouge">while</code>を使うことを推測できるはず」みたいな解くときの論理を考えながらI/O Exampleを作ることになると思うが、コンピュータでランダムに生成する場合はそういった論理なしにexampleを作るのでまとまりのないI/O exampleによるデータセットとなっている。</p>

<p>結果として、ランダム生成データセットによるPbEは、プログラミングというよりも実行Traceをうまくまとめていくパズルタスクといった方が近いように思える。</p>

<p>あるいは、そもそもDeepCoderやKarelで扱っているようなプログラムは、そもそもspecificationをIn/Outのexampleだけで与えるのが無理なのではないか、とも感じている。例えば、<code class="language-plaintext highlighter-rouge">in=[1, 3, -5], [-2, 4, 1], out=5</code>, <code class="language-plaintext highlighter-rouge">in=[9, -3, 2], [3, -6, 3], out=51</code>という2つのexampleだけからこれが「2つのリストをうけとってその内積を出力する」プログラムを求めていることを認識するのは難しいというか無理じゃないかと思う。「2つのリストの内積を計算せよ」という自然言語でのspecificationのほうが人間にとっては遥かに有用な情報となる。</p>

<p>同様にExample以外のspecificationを入力とし含むか、あるいはDSLを丁寧に設計してIn/Out exampleだけでspecificationを与えられるようにするか、したデータセットを作らないと、一定以上に複雑なProgramming by Exampleは現実的にはならないかもしれないと思っている。ただ、どちらにせよデータセットの作成にかなりの手間がかかるので、もともとのProgramming by Exampleのメリットが消えてしまうのが難点となる。</p>]]></content><author><name></name></author><summary type="html"><![CDATA[(DNNを用いた) Programming by Exampleについて、この1カ月くらいで考えていたことをまとめる。]]></summary></entry><entry><title type="html">2019年度センター試験 日本史A/B</title><link href="/ja/%E3%82%BB%E3%83%B3%E3%82%BF%E3%83%BC%E8%A9%A6%E9%A8%93/2021/05/02/exam.html" rel="alternate" type="text/html" title="2019年度センター試験 日本史A/B" /><published>2021-05-02T00:00:00+09:00</published><updated>2021-05-02T00:00:00+09:00</updated><id>/ja/%E3%82%BB%E3%83%B3%E3%82%BF%E3%83%BC%E8%A9%A6%E9%A8%93/2021/05/02/exam</id><content type="html" xml:base="/ja/%E3%82%BB%E3%83%B3%E3%82%BF%E3%83%BC%E8%A9%A6%E9%A8%93/2021/05/02/exam.html"><![CDATA[<h2 id="結果">結果</h2>

<ul>
  <li>日本史A: 71/100</li>
  <li>日本史B: 80/100</li>
</ul>

<p>最近勉強放置していたこともあり結構忘れている。日本史Aは全部近代史からで苦手意識が強いところからの出題が多かった。</p>

<p>手元のメモによると今年1月にも同じ問題を解いているらしいのだが全く覚えがない。</p>

<h2 id="メモ">メモ</h2>

<p>分かっていたことだが近代以後 (幕末～) が基本的に苦手。相対的に幕末が一番マシ、大正と戦後が特に忘れている事柄が多い。手元の教科書ではfootnoteにしか乗っていない事柄から1問でたのはちょっと厳しくないか？ という気がしたけど、センター試験だし割と受験生は覚えている/た事柄なのかな。</p>

<p>江戸以前はそれなりに大丈夫だった気がする。文化史で2問、正徳の治を何故か綱吉前だと思う理由が全く分からない勘違いで1問、村方騒動の内容を忘れていたので1問。</p>]]></content><author><name></name></author><category term="センター試験" /><summary type="html"><![CDATA[結果]]></summary></entry><entry><title type="html">Robot Program Parameter Inference via Differentiable Shadow Program Inversion メモ</title><link href="/ja/%E8%AB%96%E6%96%87/2021/04/25/arxiv.html" rel="alternate" type="text/html" title="Robot Program Parameter Inference via Differentiable Shadow Program Inversion メモ" /><published>2021-04-25T00:00:00+09:00</published><updated>2021-04-25T00:00:00+09:00</updated><id>/ja/%E8%AB%96%E6%96%87/2021/04/25/arxiv</id><content type="html" xml:base="/ja/%E8%AB%96%E6%96%87/2021/04/25/arxiv.html"><![CDATA[<p><a href="http://arxiv.org/abs/2103.14452">論文</a>, ICRA2021</p>

<hr />

<h1 id="論文内容">論文内容</h1>

<p>DNNによるinterpreterの模倣とgradient descentによる最適化を組み合わせた手法の提案。
一般的なProgram Synthesisではなく、ロボットのプログラムにおけるパラメータのチューニングが目的となっている。</p>

<h2 id="背景">背景</h2>

<p>ロボットのプログラミングでは、複数の機能 (skill) を組み合わせて所望の動作を実現することが一般的である。skillにはおのおのパラメータがありチューニングが必要となる。
人手によるパラメータチューニングでは何度も試行錯誤する必要があり、これを自動化することができるとロボットのプログラミングを簡単にすることができる。</p>

<p>微分可能プログラミング (Differentiable Programming) はパラメータチューニングを効率化できる可能性がある。プログラムが微分可能であれば、gradient basedな最適化手法によりパラメータを更新し、最適なパラメータを見つけることができる。
一方で、「プログラムが微分可能である」という制約は現実的でなく、多くのロボットプログラムのskillは微分可能な実装は普通存在しない。</p>

<h2 id="提案手法">提案手法</h2>

<p>ロボットのSkillをDNNで模倣することで微分可能な実装を作り、これを用いてパラメータ最適化を行う手法を提案した。</p>

<p>DNNの学習はSkillで完結して行い、skillの組み合わせはDNNのstackで実現する。skillの組み合わせを直接DNNで模倣しないことで学習すべき問題を簡潔にできている。</p>

<h2 id="評価">評価</h2>

<p>ロボットプログラムのベンチマーク詳しくなくて土地勘がない。</p>

<h1 id="メモコメント">メモ・コメント</h1>

<p>Program Synthesisという立場から見ると、「計算グラフ (呼び出す関数と呼び出し順) は固定で入力の定数だけ合成する」という問題設定のように見える。
templateの穴埋めみたいなケースを考えるとロボットプログラム以外のProgram Synthesisでも活用できる場面はありそう。</p>

<p>この論文における「各skillを1つのDNNで模倣し、その組み合わせはDNNのstackで模倣する」という方針は凄いpromisingに見える。この方針の利点は、1) 関数の組み合わせを考えなくてよいので学習が簡単、2) 各DNNが十分精度よくプログラムを近似できていればそれらの組み合わせの精度もある程度保証される、の2つがあると思う。2は長いプログラムのProgram Synthesisでかなり重要になるのではないかという予想。</p>]]></content><author><name></name></author><category term="論文" /><summary type="html"><![CDATA[論文, ICRA2021]]></summary></entry><entry><title type="html">Learning to Infer and Execute 3D Shape Programs メモ</title><link href="/ja/%E8%AB%96%E6%96%87/2021/04/18/arxiv.html" rel="alternate" type="text/html" title="Learning to Infer and Execute 3D Shape Programs メモ" /><published>2021-04-18T00:00:00+09:00</published><updated>2021-04-18T00:00:00+09:00</updated><id>/ja/%E8%AB%96%E6%96%87/2021/04/18/arxiv</id><content type="html" xml:base="/ja/%E8%AB%96%E6%96%87/2021/04/18/arxiv.html"><![CDATA[<p><a href="https://arxiv.org/abs/1901.02875">論文</a>, ICLR2019ポスター</p>

<hr />

<h1 id="論文内容">論文内容</h1>

<p>DNNによってプログラムのinterpreterを模倣し、gradient descentによる最適化でProgram Synthesisする手法を提案した。
研究目的はProgram Synthesisではなくて、3D物体のsemanticな識別・理解のための道具としてProgram Synthesisを用いている。</p>

<h2 id="背景">背景</h2>

<p>人間のような3D物体の理解には、物体形状に対する事前知識の利用が必要となる。一方で現在主流の方法はmeshやvoxelを3D物体のデータ形式として用いており事前知識が活用できない。
CSGNet等の手法はデータ形式としてより人間の理解しやすいprimitive (例えば直方体、球など) を用いている。しかしこれらで利用しているデータ形式は、「同じ形が繰り返されている」や「対称な形状である」のような抽象度の高い特徴を表すことはできない。</p>

<p>3D物体を表すデータ形式として、「3D物体を生成するプログラム (DSL) 」をもちいることで、このような問題を解決し人間と同じように3D物体を認識する機械学習モデルが実現できる。</p>

<h2 id="提案手法">提案手法</h2>

<p>プログラムをデータ形式として用いる課題として、新しいデータ形式であるためデータセットが存在せず機械学習の適用が難しいというものがある。</p>

<p>この問題を解決するため、A) 3D形状からプログラムを推論するDNN、A) プログラムから3D形状を推論するDNNの2つを用意し、半教師あり学習のような手法でDNNの学習を可能とした。学習自体はAとBのDNNをそれぞれ独立にランダムに生成したデータセット (3D形状とプログラムのペアが得られる) で学習している。これだけだと複雑な形状に対するProgram Synthesisがうまくいかなかった。そのため、</p>

<ol>
  <li>AのDNNでプログラムを生成</li>
  <li>BのDNNでプログラムを (近似的に実行)</li>
  <li>2の結果と欲しい3D形状でlossを計算</li>
  <li>backpropしてAの重みを更新</li>
</ol>

<p>というステップを踏み、AのDNNを修正した (guided adaptation) 。</p>

<p>guided adaptationをするにあたり、複数のstatementの結果をmax poolで統合することで可変長のプログラムに対応している。max poolで扱えるのはこの論文が扱うDSLの特徴によるもの</p>

<h2 id="評価">評価</h2>

<p>ShapeNetなどにおいて既存手法 (CSGNetなど) と比較し、提案手法が優れた数値指標を示すこと、対称性のような特徴を捉えられること、を確認した。</p>

<h1 id="メモコメント">メモ・コメント</h1>

<p>Guided Adaptationの処理自体は微分可能レンダラとかの考え方にかなり近い気がする。微分可能レンダラのほうを実際に使ったことないので間違っているかもしれないけど。</p>

<p>ランダムに生成したデータセットだけでもprogram generator (B) のDNNは十分に学習できているのがこの手法の実用性を支えている部分に見える。ただ、program generatorが近似するプログラムはかなり短いので複雑なデータセットはいらなそう。</p>

<p>一方で、interpreterをDNNで近似するProgram Synthesis手法全体を考えると、</p>

<ol>
  <li>求めている出力との差分をどう計算するか</li>
  <li>複雑なプログラムをどう実行するか</li>
</ol>

<p>あたりは難しい問題らしい。この論文だと1については3D形状が出力なので自然なロス関数があって、2については短いプログラムの結果をmax poolすることで複雑なプログラムを実行している。どちらもドメインの特徴を活用した手法なので、他ドメインに適用しようとすると問題になりそう。</p>]]></content><author><name></name></author><category term="論文" /><summary type="html"><![CDATA[論文, ICLR2019ポスター]]></summary></entry><entry><title type="html">Deep Learningによるプログラミングタスク (Program Synthesis以外)</title><link href="/ja/machinelearning/2021/04/11/deep-learning-for-programming.html" rel="alternate" type="text/html" title="Deep Learningによるプログラミングタスク (Program Synthesis以外)" /><published>2021-04-11T00:00:00+09:00</published><updated>2021-04-11T00:00:00+09:00</updated><id>/ja/machinelearning/2021/04/11/deep-learning-for-programming</id><content type="html" xml:base="/ja/machinelearning/2021/04/11/deep-learning-for-programming.html"><![CDATA[<p>Program Synthesis以外のプログラミングタスクへのDeep Learningの応用についても考えをまとめておく。</p>

<h3 id="deep-learningの適用が考えられているプログラミングタスクの種類">Deep Learningの適用が考えられているプログラミングタスクの種類</h3>

<p><a href="http://arxiv.org/abs/2102.04664">CodeXGLUEの論文</a>でベンチマークが、機械学習の分野でプログラミングを扱う際のタスクリストとして参考になりそう。CodeXGLUEの論文は以下のベンチマークを提案している。</p>

<ul>
  <li>clone detection</li>
  <li>defect detection</li>
  <li>cloze test</li>
  <li>code completion</li>
  <li>code translation</li>
  <li>code search</li>
  <li>code repair</li>
  <li>text-to-code generation</li>
  <li>code summarization</li>
  <li>documentation translation</li>
</ul>

<p>また、Related Workのsectionでは他のタスクとして”idiom mining”、”bug localization”、”test case generation”、”program synthesis”が挙げられている。この論文では別物として扱われているが、”text-to-code generation”はProgram Synthesisの一部とみなせると思う。</p>

<p>個人的には”cloze test”だけがこの論文で始めて知ったタスクだった。自然言語処理におけるMasked Language Modelみたいにソースコード中の1単語がmaskになっていて、そこに何が入るかを当てるタスクらしい。実タスクではなくて、おそらく特徴抽出能力の評価みたいな機械学習モデルそのものを評価するためのベンチマークに見える。</p>

<p>正直大半のものは試したことがなかったりで意見がない。ただ、DNNや機械学習を使うという事を考えるとプログラミング言語ごとに作りこむのは割に合わないのではないかと思っている。プログラミング言語ごとに作りこむならちゃんとプログラムの静的解析を書いたほうが良い場面が多そうなイメージがある。
だとすると、自然言語処理の応用というか流用のような形で実用的な性能になる日を待つべきなのかな、と思う。</p>

<p>タスク単位で気になるのはcode completionとcode repairの2つ。code completionは普段一番使うツールだし repairは以前から興味があって<a href="https://aaai.org/ocs/index.php/AAAI/AAAI17/paper/view/14603">DeepFix</a>データセットを使ったテストとかもしてみたので。</p>

<h3 id="code-completion">code completion</h3>

<p>DNNをcode completionに使う上で一番気になるのは実行時間。CodeXGLUEでベースラインに使われているようなTransformerを使う場合、今のテキストエディタ・IDEで使われているような時間で候補を出すのは無理だと思う。試しに手元のPC (WSL-2) でCodeGPT2の生成を回してみると、sequence length=128で700msくらい候補生成にかかっている。
Transformerの性質として、sequence lengthの二乗の計算量がかかること、実際のソースコードは128 tokenどころではないこと、を考えると厳しそう。</p>

<p>実行時間を伸ばす代わりに今のコード補完よりも長いコードを補完するという手もある。CodeXGLUEではcode completionのタスクとしてtoken-level, line-levelの2種類あるが、line-levelの方がこれに当たる。
この方針のほうがDNNを使ったコード補完としては筋がいいように思う。IDEにある他のツールと動作間隔が違うので (エディタ上で動くツールで~1secくらいでどんどん表示が更新されていく印象がある) ユーザーが慣れるまで時間かかりそうではあるけれど。</p>

<h3 id="code-repair">code repair</h3>

<p>code repairの方は、説明可能性は不要なのかというのが気になっている。今の手法を見ると大体seq2seq taskと捉えていて、「正しい修正後のコードを出すこと」を目的としている。</p>

<p>何の情報もなしに「こう変更したらエラーが直る」と言われるだけのツールで困ることはないのかな。プログラマであれば修正内容を見たらエラー原因が分かるから問題ない？ そんなパッと見てわかるようなエラーの修正ならルールベースに書くだけでできそうな気もするけど、そういった作りこみをしないで済むことがDNN/機械学習のメリットということなんだろうか。</p>]]></content><author><name></name></author><category term="MachineLearning" /><summary type="html"><![CDATA[Program Synthesis以外のプログラミングタスクへのDeep Learningの応用についても考えをまとめておく。]]></summary></entry><entry><title type="html">Neural Program Synthesisの現状と思うこと</title><link href="/ja/programsynthesis,%20machinelearning/2021/04/03/program-synthesis.html" rel="alternate" type="text/html" title="Neural Program Synthesisの現状と思うこと" /><published>2021-04-03T00:00:00+09:00</published><updated>2021-04-03T00:00:00+09:00</updated><id>/ja/programsynthesis,%20machinelearning/2021/04/03/program-synthesis</id><content type="html" xml:base="/ja/programsynthesis,%20machinelearning/2021/04/03/program-synthesis.html"><![CDATA[<p>ここ最近のDNNを用いたProgram Synthesisについて自分から見えていること、思っていることを雑にまとめてみる。</p>

<h3 id="neural-program-synthesisのカテゴリ">Neural Program Synthesisのカテゴリ</h3>

<p>Neural Program Synthesisにはいくつか種類がある。大きく、</p>

<ol>
  <li>探索の効率化手段としてDNNを用いる</li>
  <li>自然言語生成と同じ枠組みでDNNを用いる</li>
  <li>DNNでinterpreterを近似し、backpropagationでプログラムを最適化する</li>
</ol>

<p>の3つに分けられる。
ただし、1と2の違いは曖昧としたものではある。
イメージとしては1はASTを生成していて、2は文字列 (ソースコード) を生成しているイメージを持っている。</p>

<p>1については、2017年<a href="https://www.microsoft.com/en-us/research/publication/deepcoder-learning-write-programs/">DeepCoder</a>の登場後、Programming by Exampleの目的では結構つかわれている印象がある。一番最近だと<a href="https://arxiv.org/abs/2003.09040">TFCoder</a>や<a href="http://arxiv.org/abs/2007.14381">BUSTLE</a>が当てはまると思っている。</p>

<p>一方、text to code translation (自然言語を入力とするProgra Synthesis)では2が一般的な印象がある。機械翻訳と同じSeq2Seqタスクとして扱えるので実装が簡単だったとかの理由がありそう。例えば、<a href="https://sigpx.org/5/">SIGPX 5</a>で自分が紹介・その後再実装した<a href="https://arxiv.org/abs/1704.01696">NL2Code</a>が当てはまる。2020年には (Program Synthesis用ではないが) <a href="https://arxiv.org/abs/2005.14165">GPT-3</a>も登場した。</p>

<p>3は偶に出てくるが、適用できる問題設定が狭いからかあまり大きくはとりあげられていない印象がある。<a href="https://arxiv.org/abs/1901.02875">この論文</a>のような3D形状を扱うプログラミングタスクで使われている例を見る (他のタスクで見たことがない)</p>

<hr />

<h3 id="1-探索の効率化手段としてdnnを用いるについて">「1: 探索の効率化手段としてDNNを用いる」について</h3>

<p>DNNを用いたProgram Synthesisとして一番分かりやすい実装かなと思う。また、探索アルゴリズムではプログラミング言語の文法を用いてsyntaxのおかしいプログラムを排除できるので、生成したプログラムはsyntax上はvalidであることを比較的簡単に保証できる。</p>

<p>問題規模を絞って探索範囲を狭めた場合、徐々にツール化の目途が立ちつつあるように見える。<a href="https://arxiv.org/abs/2003.09040">TFCoder</a>はその一例。</p>

<p>一方、この方針で単純に問題規模を大きくし複雑なプログラムを合成する、という研究はあまりうまくいっていないように見える。
最近はProgramming by Exampleタスクであることを使って、プログラム合成 → 実行 → プログラム修正 → 実行 ….というループを回しiterativeに解法を洗練させていくアプローチをよく見る。<a href="http://arxiv.org/abs/1906.04604">この論文</a>は強化学習によってプログラムを修正している。</p>

<p>想像でしかないが、やはり一発で正しいプログラムを合成するというのは難易度が高く、(人間がやるように) テストしながらプログラムをデバッグしていく過程が必須なんじゃないかと思う。</p>

<p>また、</p>

<ul>
  <li>探索問題である以上探索回数を多くするのが性能に直結しがち</li>
  <li>プログラミング言語の文法を使った探索は複雑であまりGPU向きでない</li>
  <li>後処理でinvalidなsyntaxなものを排除するのは簡単</li>
</ul>

<p>といった点で問題規模が大きくなると、この1の方針をとるメリットが薄れがちというのもあるのでは? と思っている。</p>

<h3 id="2-自然言語生成と同じ枠組みでdnnを用いるについて">「2: 自然言語生成と同じ枠組みでDNNを用いる」について</h3>

<p>GPT-3から話題に大きく上がっている。機械翻訳と同じ枠組みで英語 → 日本語を翻訳するように英語 → Java/Python/…. を翻訳するタスクとしてProgram Synthesisを行う。</p>

<p>プログラムをsequence (文字列) として生成するため、普通にやるとsyntaxがおかしいプログラムが出力される。
2017年～2019年ごろまではこの問題への対処がホットなテーマだったように思う。<a href="https://arxiv.org/abs/1704.01696">NL2Code</a>は生成 (decode) の工夫で対処している。</p>

<p>ただ、最近はこの問題意識は重視されていなさそう。Microsoftが出したNeural Program Synthesisのベンチマークデータセットの提案<a href="http://arxiv.org/abs/2102.04664">論文</a>では後処理でsyntaxがおかしいプログラムを外しているらしい。実際一度parseすればsyntax errorがあるかどうかはすぐわかるので大量に生成して後でフィルタリングすれば良というのは合理的な気がする。</p>

<p>どの程度論理的にプログラムを生成できるかについては、調査した論文は見たことがない。ただ、個人的に実験した感覚では学習データの丸暗記 + ちょっとした変更、の域を超えるものではない印象がある。</p>

<p>GPT-3がどうなのかは出遅れてOpenAI APIにまだアクセスできないので実際のところは分からない。ただ、「GPT-3も学習済みタスクから近いものをとってきているらしい」という<a href="http://arxiv.org/abs/2102.07350">論文</a>があり、個人的にはこの話が納得がいっている。
(雑に言えば)「GPT-3はStack Overflowを暗記したのでStack Overflowにある質問なら答えることができる」みたい状況にあるのではないだろうか。</p>

<h3 id="3-dnnでinterpreterを近似しbackpropagationでプログラムを最適化するについて">「3: DNNでinterpreterを近似し、backpropagationでプログラムを最適化する」について</h3>

<p>DNNでinterpreterを近似するという手法の制約上、画像や3Dモデルに対して適用している例しかしらない。自分で試したことがないので正直勘所が分からないというのもあるので、試してみたいなぁという気持ちがある。</p>

<hr />

<h3 id="今後">今後</h3>

<p>1のような探索+枝刈りDNNという手法はツール化・実用化のフェーズに入りつつある気がする。IDE上のツールみたいな感じで実用化がゴールなのかな。例えばdoctestを書くとその場で関数の中身が合成される、というように。</p>

<p>2はホットな分野だけど、着地点がまだ見えていない気がする。Web上にあるsample programを暗記できているとすると、「ググる代わりにchatbotに聞く」みたいなアプリケーションとしての実用化が一番最初なのかもしれないと思う。</p>

<p>3は実例が少ないけど、個人的には期待している。Neural Architecture Searchがドメイン知識を利用せず微分可能にして素直にSGDで最適化、という方針が結構うまくいったのと同じように、案外多くのドメインがこの方針で高速化できたりしないのかなと思っている。
当てずっぽうでも丸暗記でもないNeural Program Synthesisを実現できそうな技術が今のところこれしか見当たらないから期待をかけている、という側面も多分にありはするけど……</p>]]></content><author><name></name></author><category term="ProgramSynthesis, MachineLearning" /><summary type="html"><![CDATA[ここ最近のDNNを用いたProgram Synthesisについて自分から見えていること、思っていることを雑にまとめてみる。]]></summary></entry><entry><title type="html">EC2(スポット)インスタンス上でChainerMNのマルチノード分散学習</title><link href="/ja/2018/08/11/ec2.html" rel="alternate" type="text/html" title="EC2(スポット)インスタンス上でChainerMNのマルチノード分散学習" /><published>2018-08-11T00:00:00+09:00</published><updated>2018-08-11T00:00:00+09:00</updated><id>/ja/2018/08/11/ec2</id><content type="html" xml:base="/ja/2018/08/11/ec2.html"><![CDATA[<p>Qiitaからの移動</p>

<hr />

<h2 id="ec2スポットインスタンスでchainermnを使うマルチノード分散学習">EC2(スポット)インスタンスでChainerMNを使う（マルチノード分散学習）</h2>

<h1 id="概要">概要</h1>
<ul>
  <li>EC2(スポット)インスタンスでChainerMNのマルチノード分散学習をする方法
    <ul>
      <li>環境変数の設定方法</li>
      <li>sshに<code class="language-plaintext highlighter-rouge">StrictHostChecking no</code>を追加</li>
      <li>セキュリティグループの設定（VPC内からの全アクセスを許可）</li>
    </ul>
  </li>
  <li>EC2上でマルチノード分散学習する場合の注意点
    <ul>
      <li><code class="language-plaintext highlighter-rouge">p2.xlarge</code>を使ってマルチノード分散学習は性能がでない</li>
      <li><code class="language-plaintext highlighter-rouge">g3.4xlarge</code>を利用すると良い</li>
    </ul>
  </li>
  <li>マルチノード学習した際の性能の簡単な評価
    <ul>
      <li>ImageNetの学習では<code class="language-plaintext highlighter-rouge">p2.8xlarge</code>を使う時と同等かそれ以上のコストパフォーマンス</li>
    </ul>
  </li>
</ul>

<h1 id="やりたかったこと">やりたかったこと</h1>
<p>スポットインスタンスの価格が比較的安いGPU1個のインスタンス（<code class="language-plaintext highlighter-rouge">p2.xlarge</code>や<code class="language-plaintext highlighter-rouge">g3.4xlarge</code>）を複数使って、ディープラーニングの学習を高速化させたかった。</p>

<p>学習を高速にする手段としては、マルチノードで分散する以外に、そもそも1台あたりのGPU数を増やす、という選択肢もある。
しかし、GPUを複数個積んでいるEC2のインスタンスはどれも高いし、スポットインスタンスで価格を抑えられないことがある。例えば、<code class="language-plaintext highlighter-rouge">p2.8xlarge</code>はオンデマンドインスタンスの場合、$7.2/hかかる。スポットインスタンスの価格は、ここ1週間くらいは<code class="language-plaintext highlighter-rouge">p2.8xlarge</code>が$2.5/h弱のようだが、ちょっと前は$72/hに張り付いていた。
あるいは、自前で学習用計算機用意する手もあるが、GPU複数台積むマシンとなるとかなり高くつくことになる。個人の趣味の範囲内だと、電気代を抜いてもAWSを使うより高くなる可能性が高そう。</p>

<p>なので、<code class="language-plaintext highlighter-rouge">p2.xlarge</code>などのスポットインスタンスでの値段が低め（〜$0.3/h）で抑えられているインスタンスを複数利用して、学習を高速化させるという方針に至った。オンデマンドの<code class="language-plaintext highlighter-rouge">p2.8xlarge</code>と比べて、スポットインスタンスの<code class="language-plaintext highlighter-rouge">p2.xlarge</code>や<code class="language-plaintext highlighter-rouge">g3.4xlarge</code>は1GPU当たりの値段で1/3ほどなので、マルチノードの分散学習の複雑さや効率の悪さはGPUの台数で補えるという目論見。</p>

<h1 id="chainermnを使った分散学習-in-aws">ChainerMNを使った分散学習 in AWS</h1>
<p>環境の準備
—</p>
<h3 id="chainermnのインストール">ChainerMNのインストール</h3>
<p>ChainerMNをインストールする方法自体は、もう多数の記事・情報があるので、詳細は省く。自分は<a href="http://qiita.com/pst-ic/items/e01033dee4d389df3a5e">ここ</a>と<a href="http://chainermn.readthedocs.io/en/latest/installation/index.html">ChainerMNのチュートリアル</a>を参考にした。
やったことを列挙すると、以下の通り。</p>

<ul>
  <li>CUDA 8.0のインストール</li>
  <li>cuDNN 6.0のインストール</li>
  <li>NCCL 1.xのインストール
    <ul>
      <li>GitHubのページにはno longer maintainedとあるが、まだNCCL2は使えかった</li>
    </ul>
  </li>
  <li>OpenMPIのビルド・インストール</li>
  <li>Chainer、ChainerMNのインストール</li>
</ul>

<p>この作業はGPUを積んでいる中で安いインスタンス（<code class="language-plaintext highlighter-rouge">p2.xlarge</code>）を利用すると良い。</p>

<h3 id="環境変数の設定">環境変数の設定</h3>
<p>sshに非対話モードで入った時に、<code class="language-plaintext highlighter-rouge">CPATH</code>や<code class="language-plaintext highlighter-rouge">LD_LIBRARY_PATH</code>が適切な値（具体的にはcudaのパスを含む）になっていないと学習スクリプトがうまく動かない。
<code class="language-plaintext highlighter-rouge">/etc/bash.bashrc</code>を以下のようにした。</p>

<pre><code class="language-bash:/etc/bash.bashrc">export PATH=/usr/local/cuda-8.0/bin:${PATH}
export LD_LIBRARY_PATH=/usr/local/cuda-8.0/lib64:${LD_LIBRARY_PATH}
export CPATH=/usr/local/cuda-8.0/targets/x86_64-linux/include:${CPATH}
</code></pre>

<p>以下のコマンドを叩いた時、<code class="language-plaintext highlighter-rouge">PATH</code>や<code class="language-plaintext highlighter-rouge">LD_LIBRARY_PATH</code>が適切に設定されていれば良い。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>ssh localhost <span class="s1">'env'</span>
</code></pre></div></div>

<h3 id="sshの設定">sshの設定</h3>
<p>マルチノード分散学習をする際、インタラクティブな操作なしに別ノードへsshで接続できる必要がある。したがって、鍵認証の設定をする。また、デフォルトでは最初に接続しようとすると、<code class="language-plaintext highlighter-rouge">Are you sure you want to continue connecting (yes/no)? </code>のメッセージが出て、yes/noの入力を求められるので、手間を考えるとこれも対処する必要がある。</p>

<p>まず、鍵認証の設定をする。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>ssh-keygen <span class="c">#パスフレーズなし、~/.ssh/id_rsaに置く</span>
<span class="nv">$ </span><span class="nb">cat</span> ~/.ssh/id_rsa.pub <span class="o">&gt;&gt;</span> ~/.ssh/authorized_keys
</code></pre></div></div>

<p>次に、<code class="language-plaintext highlighter-rouge">.ssh/config</code>を以下のとおりにして、yes/no入力をなくす</p>

<pre><code class="language-~/ssh/.config">Host *
    StrictHostKeyChecking no
</code></pre>

<p>どちらもセキュリティ上良いとは言えないが、最終的にはAWSのセキュリティグループで外部ネットワークからのインバウンドを遮断して運用すれば許容範囲と思っている。</p>

<h3 id="enaの有効化">ENAの有効化</h3>
<p>必要なのかはわからないが、UbuntuはデフォルトではENAが有効になっていないようだったので、有効にする。最新の手順は<a href="http://docs.aws.amazon.com/ja_jp/AWSEC2/latest/UserGuide/enhanced-networking-ena.html#enhanced-networking-ena-ubuntu">ここ</a>にあるので、これの通りに行う。
やるべきことは以下の3つ</p>

<ol>
  <li>インスタンス上で、ENAのモジュールを追加</li>
  <li>インスタンスを停止</li>
  <li>ローカルからaws CLIでENAを有効化</li>
</ol>

<h3 id="aws上のリソースの準備">AWS上のリソースの準備</h3>
<h4 id="1-vpcサブネットプレイスメントグループの準備">1. VPC、サブネット、プレイスメントグループの準備</h4>
<p>それぞれ適当な名前で準備する。VPCとサブネットは一度EC2インスタンスを起動すればついでにできるし、プレイスメントグループは、EC2のコンソールから、ネットワーク&amp;セキュリティ → プレイスメントグループのページに行って作成すれば良い。
なお、プレイスメントグループはいるのかどうか分からないが、ネットワークの帯域幅をフルに出すには必要らしいので自分は作成した。</p>

<h4 id="2-学習ノード用のセキュリティグループの準備">2. 学習ノード用のセキュリティグループの準備</h4>
<p>セキュリティグループの準備も必要。インバウンドルールでは、「すべてのトラフィック・すべてのポート範囲へのVPCからのアクセス」を許可する。本来はもっと絞りこめると思うが、調べるのが面倒だったのでVPC内に全部公開した。
EC2コンソール上では、<code class="language-plaintext highlighter-rouge">すべてのトラフィック すべて 0-65535 カスタム &lt;VPCのCIDR&gt;</code>となっていれば良い。</p>

<h4 id="3-optional-amiの作成">3. (Optional) AMIの作成</h4>
<p>必要はないが、ここまで終えた時点でAMIを作っておくと別のことをしたい時に無駄な出費を防げる。
AMIの作成方法は省略。</p>

<h3 id="学習スクリプトなどの準備">学習スクリプトなどの準備</h3>
<p>最後に、学習用のスクリプト、データセットなどを準備する。</p>

<p>今回、自分はchainermnについているImageNetのサンプルを使った。
<code class="language-plaintext highlighter-rouge">git clone --depth 1 https://github.com/chainer/chainermn.git</code>として、chainermnのソースを落とすと<code class="language-plaintext highlighter-rouge">chainermn/examples/imagenet</code>の下にImageNetのサンプルがあるのでこれを用いる。また、自分の場合、<code class="language-plaintext highlighter-rouge">models_v2/nin.py</code>をchainerの<code class="language-plaintext highlighter-rouge">examples/imagenet/nin.py</code>に置き換えないと動かなかったので、chainerのソースも落としてきて<code class="language-plaintext highlighter-rouge">cp</code>した。</p>

<p>次に、データセットを準備する。データセットの準備方法は、<a href="http://d.hatena.ne.jp/shi3z/20150709/1436397615">ここ</a>や<a href="http://pongsuke.hatenadiary.jp/entry/2017/03/15/101127">ここ</a>などが参考になる。</p>

<p>ここまで終えたら、インスタンスを止めてAMIを作成する。</p>

<h2 id="実行方法1ノード">実行方法（1ノード）</h2>
<p>テストも兼ねて1ノードで学習を走らせる場合は、インスタンスを起動した後、sshでログインして、</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>mpiexec <span class="nt">-n</span> 1 python3 ~/chainermn/examples/imagenet/train_imagenet.py train.txt test.txt
</code></pre></div></div>

<p>などとすれば良い。ここで、train.txt、test.txtはそれぞれ準備したデータセットのパス</p>

<p><strong>参考</strong>: <a href="http://chainermn.readthedocs.io/en/latest/tutorial/step1_communicators_optimizers.html#run">ChainerMN チュートリアル</a></p>

<h2 id="実行方法マルチノード">実行方法（マルチノード）</h2>

<p>上で作成した学習スクリプトの入ったAMIを利用し、スポットインスタンスを適当に何個か立ち上げる。この時、VPC、プレイスメントグループ、セキュリティグループは上で準備したものを忘れず利用する。
なお、別にスポットインスタンスでなくてもいいが、費用を抑えて実験してみたいだけならスポットインスタンスの方が適していると思う。ただし、スポットインスタンスが突然中断するリスクを減らすため、高めに価格を設定しておくと安心。</p>

<p>また、多少値段は上がるが、<code class="language-plaintext highlighter-rouge">p2.xlarge</code>でなく、<strong><code class="language-plaintext highlighter-rouge">g3.4xlarge</code>を使うと良い</strong> (理由は”注意点”で後述)。</p>

<p>以下では、2台の<code class="language-plaintext highlighter-rouge">g3.4xlarge</code>インスタンスを立ち上げ、それぞれのプライベートIPが<code class="language-plaintext highlighter-rouge">172.31.41.13</code>、<code class="language-plaintext highlighter-rouge">172.31.41.14</code>となったとする。
まず、どちらか1台（以下では<code class="language-plaintext highlighter-rouge">172.31.41.13</code>の方とする）にsshでログインする。ログインしたら、以下の内容のホストファイルを<code class="language-plaintext highlighter-rouge">~/hostfile</code>に作成する（パスはどこでも良い）。</p>

<pre><code class="language-:~/hostfile">172.31.41.13 cpu=1
172.31.41.14 cpu=1
</code></pre>
<p>（プライベートIPは、その時立ち上げたスポットインスタンスを見て適宜修正する必要あり。）</p>

<p>次に、以下のコマンドを叩くと、2台のマシンで分散学習される。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>mpiexec <span class="nt">-n</span> 2 <span class="nt">--hostfile</span> ~/hostfile python3 ~/chainermn/examples/imagenet/train_imagenet.py train.txt test.txt
</code></pre></div></div>

<p><strong>参考</strong>: <a href="http://chainermn.readthedocs.io/en/latest/tutorial/step1_communicators_optimizers.html#multi-node-execution">ChainerMN チュートリアル</a></p>

<h3 id="注意点ネットワークの帯域幅を考慮する必要あり">注意点（ネットワークの帯域幅を考慮する必要あり）</h3>
<p>GPU付きインスタンスの中では<strong><code class="language-plaintext highlighter-rouge">p2.xlarge</code>が値段は安いのだが、ネットワークの帯域幅が小さく、性能が出なかった</strong>。iperfを使ってはかった結果では、<code class="language-plaintext highlighter-rouge">1.44Gbps</code>。一方、<code class="language-plaintext highlighter-rouge">g3.4xlarge</code>は<code class="language-plaintext highlighter-rouge">10Gbps</code>でるというスペックだし、実際iperfではかると10Gbpsでた（情報提供：https://twitter.com/grafi_tt/status/895274632177000449 ）。</p>

<p>いくら安く分散学習させたいと言っても、<code class="language-plaintext highlighter-rouge">p2.xlarge</code>だと性能向上が見られなかったので、<code class="language-plaintext highlighter-rouge">g3.4xlarge</code>を使う方が良いと思う。</p>

<h1 id="性能確認">性能確認</h1>
<p>学習が高速化できるのか確認するため簡単な性能測定をした。なお、どれも1回しか計測してないし、真面目に条件を揃えたわけではないので、数字は参考程度に。</p>

<p>以下のパターンで、ImageNetの学習にかかる時間を測定した。</p>

<ol>
  <li><code class="language-plaintext highlighter-rouge">g3.4xlarge</code>1台で、ChainerMNを利用</li>
  <li><code class="language-plaintext highlighter-rouge">g3.4xlarge</code>複数台（2, 4, 6, 8, 10, 12)で、ChainerMNを利用</li>
  <li><code class="language-plaintext highlighter-rouge">p2.8xlarge</code>(8GPU)で、ChainerMNを利用</li>
</ol>

<h2 id="結果">結果</h2>

<p>以下の通り。
分散すればちゃんと高速化されるし、<code class="language-plaintext highlighter-rouge">p2.8xlarge</code>と比べても安いまたは同等程度の値段でほぼ同じ性能を出せている。ただ、この辺は学習させるネットワークやデータセ��トによって色々異なるんだろうな。</p>

<p><strong>表1: 1エポック当たりの時間</strong></p>

<table>
  <thead>
    <tr>
      <th style="text-align: left">条件</th>
      <th style="text-align: left">1エポックあたりの平均時間 (sec)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">g3.4xlarge*1</code></td>
      <td style="text-align: left">34.4</td>
    </tr>
    <tr>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">g3.4xlarge*2</code></td>
      <td style="text-align: left">21.8</td>
    </tr>
    <tr>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">g3.4xlarge*4</code></td>
      <td style="text-align: left">12.5</td>
    </tr>
    <tr>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">g3.4xlarge*6</code></td>
      <td style="text-align: left">9.2</td>
    </tr>
    <tr>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">g3.4xlarge*8</code></td>
      <td style="text-align: left">7.9</td>
    </tr>
    <tr>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">g3.4xlarge*10</code></td>
      <td style="text-align: left">6.3</td>
    </tr>
    <tr>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">g3.4xlarge*12</code></td>
      <td style="text-align: left">5.2</td>
    </tr>
    <tr>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">p2.8xlarge</code></td>
      <td style="text-align: left">7.9</td>
    </tr>
  </tbody>
</table>

<p>ちゃんと分散するにつれて短い時間で学習できている。</p>

<hr />

<p><strong>表2: 値段 - 総実行時間</strong></p>

<table>
  <thead>
    <tr>
      <th style="text-align: left">条件</th>
      <th style="text-align: left">値段 ($/h)</th>
      <th style="text-align: left">総実行時間 (sec)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">g3.4xlarge*1</code></td>
      <td style="text-align: left">0.3</td>
      <td style="text-align: left">344.3</td>
    </tr>
    <tr>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">g3.4xlarge*2</code></td>
      <td style="text-align: left">0.6</td>
      <td style="text-align: left">217.8</td>
    </tr>
    <tr>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">g3.4xlarge*4</code></td>
      <td style="text-align: left">1.2</td>
      <td style="text-align: left">125.2</td>
    </tr>
    <tr>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">g3.4xlarge*6</code></td>
      <td style="text-align: left">1.8</td>
      <td style="text-align: left">92.4</td>
    </tr>
    <tr>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">g3.4xlarge*8</code></td>
      <td style="text-align: left">2.4</td>
      <td style="text-align: left">79.2</td>
    </tr>
    <tr>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">g3.4xlarge*10</code></td>
      <td style="text-align: left">3.0</td>
      <td style="text-align: left">63.0</td>
    </tr>
    <tr>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">g3.4xlarge*12</code></td>
      <td style="text-align: left">3.6</td>
      <td style="text-align: left">51.7</td>
    </tr>
    <tr>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">p2.8xlarge</code></td>
      <td style="text-align: left">7.2(オンデマンド) / 2.5(スポットインスタンス利用時)</td>
      <td style="text-align: left">79.1</td>
    </tr>
  </tbody>
</table>

<p>備考：<code class="language-plaintext highlighter-rouge">g3.4xlarge</code>のスポットインスタンスの値段は$0.3/hとして計算</p>

<p><code class="language-plaintext highlighter-rouge">p2.8xlarge</code>をオンデマンドで利用する場合に比べると、より安く高速な学習ができる。<code class="language-plaintext highlighter-rouge">p2.8xlarge</code>がスポットインスタンスの場合と比べても、ほぼ同等の性能が今回の例では出た。</p>

<hr />

<p><strong>グラフ1: epoch - elapsed_time</strong>
<img src="https://qiita-image-store.s3.amazonaws.com/0/111070/e3662fc5-bd4c-b7c2-e6d9-31f0ec56e3f7.png" alt="graph1.png" width="1000px" /></p>

<hr />

<p><strong>グラフ2: epoch-validation/main/accuracy</strong>
<img src="https://qiita-image-store.s3.amazonaws.com/0/111070/753d6611-72bb-a402-cda2-80986f32346a.png" alt="graph2.png" width="1000px" /></p>

<p>epochが少なすぎてわかりやすいデータにならなかったが、分散させるほど同エポックでの精度は悪化する傾向にあるらしい。直感的にもそんな気はする。とはいえ、マルチノードの場合と<code class="language-plaintext highlighter-rouge">p2.8xlarge</code>でノード内で分散した場合では大きな精度の差は見つけられない。分散学習するなら、エポックを大きめに設定する必要があるようだが、それはマルチノード分散学習の問題というより、現在のChainerMN全体の問題の可能性が高い。</p>

<hr />

<p><strong>その他備考</strong>：
分散学習では、最初の1回の<code class="language-plaintext highlighter-rouge">mpiexec</code>は時間がかかるらしい。上記計測は、2回目の<code class="language-plaintext highlighter-rouge">mpiexec</code>で行っている。原因は、ノード間の接続を確立する時間が追加されているからではないかと思うが、詳細は不明。ただし、学習時間が長くなるにつれて、その時間は無視できるものになると思��れる。</p>

<h1 id="まとめとか">まとめとか</h1>
<p>少なくともImageNetでは、マルチノードの分散学習でも相当の学習時間の短縮が見込める。また、8/7からChainerMNを初めて5日でここまでできたので、非常に難しい作業が必要というわけでもない。
そのため、AWS上でのディープラーニング学習を高速化させたい時、選択肢に入れる価値はあると思う。最初に書いたような、複数GPUを積んだスポットインスタンスが高い時にも使えるし、あるいは<code class="language-plaintext highlighter-rouge">p2.8xlarge</code>を複数使ってさらに高速化する、という使い方もマルチノードの分散学習はできるはず。</p>

<p>一方で、データセットが増えた時どうなるのか、モデルが複雑になった時どうなるのか、などは調べてない。実際に使ってみるとたいして高速化されなかった、みたいなケースはありそう。</p>

<h2 id="要改善点">要改善点</h2>
<p>とりあえずテストするだけなら上記手順でもできたが、実際にディープラーニングを利用するプロジェクトに組み込むとなると以下の点を改善しないといけない。</p>

<h4 id="学習スクリプトの実行方法">学習スクリプトの実行方法</h4>
<p>本来は、aws CLIとかSDKからスポットインスタンスを立ち上げて、自動で学習を回したい（<a href="http://qiita.com/halhorn/items/ae402e8c22bc1083ff23">ここ</a>みたいに）。
そのためには、<code class="language-plaintext highlighter-rouge">UserData</code>のスクリプトで学習スクリプトを実行する必要があるが、以下の点に注意が必要。</p>

<ol>
  <li><code class="language-plaintext highlighter-rouge">mpiexec</code>をするインスタンスの決定方法</li>
  <li>ホストファイルの作成方法</li>
  <li>すべてのインスタンスが立ち上がるまでの待ち合わせ処理</li>
</ol>

<p>1については、特定のタグを全インスタンスに付けておき、<code class="language-plaintext highlighter-rouge">aws ec2 describe-instances</code>で全インスタンスのプライベートIPを取得、辞書順最小のインスタンスで<code class="language-plaintext highlighter-rouge">mpiexec</code>すれば解決しそう。
2は、<code class="language-plaintext highlighter-rouge">describe-instances</code>した時に全部のプライベートIPがわかるんだからホストファイルもついでに生成できる。
3は、ポーリングなりなんなりでやればできるはず。この時、ついでに学習パラメータの環境変数への展開やS3からデータセットのダウンロードも待ち合わせ処理すると色々便利そう。</p>

<h4 id="中断時の対処">中断時の対処</h4>
<p>スポットインスタンスなので、たまに強制終了させられることがある。</p>

<ol>
  <li>定期的なS3へのスナップショットアップロード（systemd-timer）</li>
  <li>1台でも終了したら全台終了して無駄な出費の削減</li>
  <li>学習開始時にスナップショットがあればそれを読み込み</li>
</ol>

<p>の3つの対処が必要。</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Qiitaからの移動]]></summary></entry></feed>