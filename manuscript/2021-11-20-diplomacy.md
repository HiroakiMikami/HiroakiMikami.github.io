<!--
---
layout: post
title: 機械学習を用いたディプロマシーのagent作成
subtitle: 
---

個人的にディプロマシーをよくやっていた (最近はやれていないが) ので、機械学習でゲームエージェントをどのくらい作れるのか気になっている。


ディプロマシーについて
===

- 基礎情報
    - 原則7人で遊ぶゲーム
    - 1901年 (第一次大戦直前) のヨーロッパの支配を目指すボードゲーム
- ボードゲームとしてのポイント
    - ゲームシステムにはランダムな要素は存在しない
    - 外交フェーズによる口約束と行軍フェーズにおけるその裏切りがポイントとされる
- ただ、ゲームとしては「裏切るゲーム」ではなくて「信頼できる相手を1国見つけてそこと最後の最後まで協力するゲーム」のほうが恐らく正しい
    - 定石として
        - 短期的な行軍での裏切りは必要
        - 長期的な展望での裏切りは行わない (方が良いとされていると思う)
    - ゲームの勝ち方や情勢に対する価値観の共有ができるかどうかがポイント
- 一般論としては
    - 西欧 (英独仏) と東欧 (墺伊露土) の間で多数派になれるように立ち回る
    - 自分と逆側に最終盤面まで協力できる同盟国を見つける
    - 中盤～終盤でGSLを超えて補給都市を確保して制覇へ


論文
===

RLの文脈でいくつかでている。

- with human play data
- without human replay


論文まとめ
---

- 課題
    - 考えないといけない場合の数が多い
        - パターンが多い (全ユニットが同時に動くかつ動き方が多様)
        - 長期にわたる検討が必須
    - 自然言語による外交が本来必要
- アプローチ
    - 場合の数が多い => DeepRLによる学習
    - 外交 => No Press versionによって一旦回避


論文で気になる点
---

- rewardの定義
    - 制覇した時は明らかに+1で滅亡した時は0 or -1
    - 制覇せずに終わる (所謂引き分けの時) は占領した都市の数でrewardを定義している
        - Diplomacyを遊ぶ時によく問題になることの1つ
            - ルールブックを読む限り、制覇は勝ち、滅亡は負け、他は引き分けで差はないゲーム
            - 制覇は非常に難しいので、「占領した都市が多いと勝ち」にしちゃうと制覇を目指さないのが最適になってしまう
        - とはいえsparseな報酬はRLの学習をうまくいかなくさせるのも理解できる
    - human play logがあれば緩和できるだろうがself-playだけで本当にこれは学習できるのか?
        - 制覇できないが補給都市7~10あたりを堅実に確保して終わりという戦略は1ディプロマシープレイヤーとしてはそれは違うという気持ちがある。ルールブックを読む限り制覇できなければ引き分けであって補給都市の個数は勝敗に関係ない。
        - ただ、短期的な利益と長期的な利益は間違いなく矛盾したゲームだと思う
        - リアルでやる時で「2年くらいやって補給都市最大の国が勝ち」だとドイツが初手で対墺するのは有効な時はあるが、制覇まで目指すならそれは厳しい
- ローカルなお約束のようなもの存在すると思う (人間は過学習している)
    - Belの扱い
        - 1901年はBelを空白にしておく
        - Belを英が仏に渡して陸軍作ってもらう
    - ロシアの初期行軍 (70年代ごろの記録を見ると北方OPが主流だったこともあるらしい)


気になる点
===

ディプロマシープレイヤーとして
---

- 初動の最適解は存在するのか?
    - フランスの場合、初手対独をするとGSLの突破と対英の両立ができず詰むというのはよくあるパターン
    - これはドイツも同様なので、仏独は協同対英をどこかでせざるを得ないと思っている。英は伊の手助けを借りつつ包囲網の突破を測るのが前半の原則と思う。
    - なんとなく制覇を目指すときに初手が決まりがちな国ってあると思うが、それは本当なのか?
- 「お約束」から外れたプレイヤーはどう扱うのが正しいのか?


機械学習として
---

- 未知のプレイヤーへの対応はできるのか (局所解に入らないのか)
    - 人間は局所解に入っている気がする
- 外交を組み込めるようになるのか
    - 長期間一貫して論理のある会話ができないといけない。
    - 今の自然言語処理の延長でこれができるようになる気はあまりしていない。
        - 言語モデルって割とWeb上にあるデータを覚えているだけなんじゃないかと思うんだけどどうなんだろう。
        - ディプロマシーのプレイログを覚えられれば良いという可能性はある?
        - 同じ状態でも抱いている戦略によって返答は変わると思う。

-->